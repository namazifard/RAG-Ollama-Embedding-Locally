# Retrieval Augmented Generation (RAG) system using Ollama Embedding; "nomic-embed-text" Model

Streamlit application for PDF-based Retrieval-Augmented Generation (RAG) using Ollama + LangChain.

## Running the Streamlit application

1. **Clone repo**: Run this in your terminal 

      ```bash
      git clone https://github.com/namazifard/RAG-Ollama-Embedding-Locally.git
      cd RAG-Ollama-Embedding-Locally
      ```

2. **Install Dependencies**: Execute to install dependencies
  
      ```bash
      pip install -r requirements.txt
      ```

3. **Launch the App**: Run to start the Streamlit interface on `localhost`

      ```bash
      streamlit run streamlit_app.py
      ```

This application allows users to upload a PDF, process it, and then ask questions about the content using a selected language model.
